"""Tidy bibtex keys generated using the BibTex_Auburn.csl style.

The new key format is: firstauthorlastname:journalbibtexkey:year

The journal_to_bibtexkey dictionary maps journal names to their corresponding
bibtex keys. If a journal is not found in the dictionary, a warning is printed
and a default key is generated by lowercasing the journal name and removing
spaces and special characters. Please expand the dictionary as needed. Long-term,
consider automating the generation of this dictionary from a reliable source or
maintaining it in a separate, shared JSON or YAML file.

Requirements:
    unidecode (install via pip if not already installed)

Command line arguments:
    -f: Path to the bib file to process.
    -i: A single bibtex entry to process.

Notes:
    If using -f, the original file is untouched; a -tidied.bib file is created.
    Only @article entries are processed; other entry types are ignored and
    retained as-is at the end of the file.
"""

import argparse
import os
import sys
from unidecode import unidecode

parser = argparse.ArgumentParser(description="Process a file.")
parser.add_argument("-f", dest="filename", type=str, help="Path to the bib file")
parser.add_argument("-i", dest="entry", type=str, help="Bibtex entry to process")
args = parser.parse_args()

if args.filename is None and args.entry is None:
    print("Please provide either a filename with -f or an entry with -i.")
    sys.exit(1)
elif args.filename is not None and args.entry is not None:
    print("Please provide only one of -f or -i.")
    sys.exit(1)

# Dictionary mapping journal names to bibtex keys
# Expand this dictionary as needed
journal_to_bibtexkey = {
    "ACS Applied Materials & Interfaces": "acsapplmaterinterfaces",
    "ACS Applied Nano Materials": "acsapplnanomater",
    "ACS Catalysis": "acscatal",
    "ACS Energy Letters": "acsenergylett",
    "ACS Macro Letters": "acsmacrolett",
    "ACS Nano": "acsnano",
    "ACS Photonics": "acsphotonics",
    "ACS Sensors": "acssensors",
    "AIAA Journal": "aiaaj",
    "AIChE Journal": "aichej",
    "APL Materials": "aplmater",
    "Accounts of Chemical Research": "accchemres",
    "Accounts of Materials Research": "accmaterres",
    "Advanced Materials": "advmater",
    "Advances in Colloid and Interface Science": "advcolloidinterfacesci",
    "Analytical and Bioanalytical Chemistry": "analbioanalchem",
    "Annual Review of Chemical and Biomolecular Engineering": "annurevchembiomoleng",
    "Annual Review of Materials Research": "annurevmaterres",
    "Applied Physics Letters": "applphyslett",
    "Applied Surface Science": "applsurfsci",
    "Biophysical Journal": "biophysj",
    "Biosensors": "biosensors",
    "Biosensors and Bioelectronics": "biosensbioelectron",
    "Chemical Communications": "chemcommun",
    "Chemical Physics": "chemphys",
    "Chemical Reviews": "chemrev",
    "Chemical Society Reviews": "chemsocrev",
    "Chemistry of Materials": "chemmater",
    "ChemPhysChem": "chemphyschem",
    "Clean Products and Processes": "cleanprodprocess",
    "Computational Materials Science": "computmatersci",
    "Computer Physics Communications": "computphyscommun",
    "Computers & Chemical Engineering": "computchemeng",
    "Current Opinion in Chemical Engineering": "curopinchemeng",
    "Current Opinion in Solid State and Materials Science": "curopinsolidstatematersci",
    "Engineering with Computers": "engcomput",
    "Entropy": "entropy",
    "European Journal of Operational Research": "eurjoperres",
    "European Polymer Journal": "eurpolymj",
    "Europhysics Letters": "epl",
    "Frontiers in Bioengineering and Biotechnology": "frontbioengbiotechnol",
    "IEEE Transactions on Cybernetics": "ieeetranscybern",
    "Industrial & Engineering Chemistry Research": "indengchemres",
    "Inorganic Chemistry": "inorgchem",
    "International Journal for Numerical Methods in Engineering": "intjnummethodseng",
    "Journal of Chemical & Engineering Data": "jchemengdata",
    "Journal of Chemical Information and Modeling": "jcheminfmodel",
    "Journal of Chemical Theory and Computation": "jctc",
    "Journal of Colloid and Interface Science": "jcolloidinterfacesci",
    "Journal of Computational Chemistry": "jcomputchem",
    "Journal of Economic Dynamics and Control": "jecondyncontrol",
    "Journal of Global Optimization": "jgloboptim",
    "Journal of Hazardous Materials": "jhazardmater",
    "Journal of Materials Chemistry": "jmaterchem",
    "Journal of Membrane Science": "jmembrsci",
    "Journal of Molecular Biology": "jmolbiol",
    "Journal of Molecular Catalysis A: Chemical": "jmolcatala",
    "Journal of Molecular Graphics": "jmolgraph",
    "Journal of Open Source Software": "jopensource",
    "Journal of Pharmacy and Bioallied Sciences": "jpharmbioalliedsci",
    "Journal of Physics: Condensed Matter": "jphyscondensmatter",
    "Journal of Quantitative Spectroscopy and Radiative Transfer": "jquantspectroscradtrans",
    "Journal of Rheology": "jrheol",
    "Journal of The Royal Society Interface": "jrsocinterface",
    "Journal of the American Chemical Society": "jamchemsoc",
    "Langmuir": "langmuir",
    "Laser & Photonics Reviews": "laserphotonicsrev",
    "MRS Bulletin": "mrsbull",
    "Macromolecular Rapid Communications": "macromolrapidcommun",
    "Macromolecular Theory and Simulations": "macromoltheorysimul",
    "Macromolecules": "macromolecules",
    "Materials Horizons": "materhoriz",
    "Modelling and Simulation in Materials Science and Engineering": "modelsimmaterscieng",
    "Molecular Physics": "molphys",
    "Molecular Simulation": "molsimul",
    "Molecular Systems Design & Engineering": "molsystdeseng",
    "Nature": "nature",
    "Nature Chemistry": "natchem",
    "Nature Communications": "natcommun",
    "Nature Materials": "natmater",
    "Nature Methods": "natmethods",
    "Nature Nanotechnology": "natnanotechnol",
    "Nature Reviews Materials": "natrevmater",
    "Nano Letters": "nanolett",
    "Nano Today": "nanotoday",
    "Nanoscale": "nanoscale",
    "Nanoscale Advances": "nanoscaleadv",
    "Organometallics": "organometallics",
    "PLOS Computational Biology": "ploscomputbiol",
    "PLOS ONE": "plosone",
    "Petroleum Chemistry": "petchem",
    "Physical Chemistry Chemical Physics": "physchemchemphys",
    "Physical Review A": "physreva",
    "Physical Review E": "physreve",
    "Physical Review Letters": "physrevlett",
    "Physical Review X": "physrevx",
    "Polymer": "polymer",
    "Polymer Journal": "polymj",
    "Proceedings of the National Academy of Sciences": "procnatlacadsciusa",
    "Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences": "procrsoca",
    "Progress in Surface Science": "progsurfsci",
    "RSC Advances": "rscadv",
    "Research in Engineering Design": "resengdes",
    "SIAM Journal on Scientific Computing": "siamjscicomput",
    "Science": "science",
    "Science Advances": "sciadv",
    "Scientific Reports": "scirep",
    "Sensing and Bio-Sensing Research": "sensbiosensres",
    "Sensors": "sensors",
    "Sensors and Actuators B: Chemical": "sensactuatorsb",
    "Separation and Purification Technology": "seppuriftechnol",
    "Small": "small",
    "Soft Matter": "softmatter",
    "SoftwareX": "softwarex",
    "The European Physical Journal B": "eurphysjb",
    "The Journal of Chemical Physics": "jchemphys",
    "The Journal of Physical Chemistry A": "jpca",
    "The Journal of Physical Chemistry B": "jpcb",
    "The Journal of Physical Chemistry C": "jpcc",
    "The Journal of Physical Chemistry Letters": "jphyschemlett",
    "TrAC Trends in Analytical Chemistry": "tractrendsanalchem",
    "WIREs Computational Molecular Science": "wirescomputmolsc",
    "WIREs Computational Statistics": "wirescomputstat",
    "WIREs Data Mining and Knowledge Discovery": "wiresdataminknowldisc",
    "npj Computational Materials": "npjcomputmater",
}


def process_article(entry):
    error = False
    error_message = ""

    # get key between { and ,
    start_index = entry.find("{") + 1

    # find the num_commas + 1 th comma after start_index
    if entry.find("journal={") != -1:
        # get journal field
        journal_start = entry.find("journal={") + len("journal={")
        journal_end = entry.find("}", journal_start)
        journal = entry[journal_start:journal_end].strip()

        # count number of commas in journal name
        num_commas = journal.count(",")

        if num_commas == 0:
            end_index = entry.find(",", start_index)
        else:
            comma_index = start_index
            for _ in range(num_commas + 1):
                comma_index = entry.find(",", comma_index + 1)
            end_index = comma_index
    else:
        error = True
        error_message += "Journal field not found in entry.\n"

    if entry.find("year={") == -1:
        error = True
        error_message += "Year field not found in entry.\n"
    
    if error:
        key = ""
    else:
        key = entry[start_index:end_index].strip()

    # get first author part of key
    # get first authors last name
    # start of key to first _ or : which ever comes first
    author_end_index = len(key)
    underscore_index = key.find("_")
    colon_index = key.find(":")

    if underscore_index != -1 and underscore_index < author_end_index:
        author_end_index = underscore_index
    if colon_index != -1 and colon_index < author_end_index:
        author_end_index = colon_index

    first_author = key[:author_end_index]

    # make first author name lowercase
    first_author = first_author.lower()

    # remove accents from first author name
    first_author = unidecode(first_author)

    # remove everything before . in first author name
    if "." in first_author:
        first_author = first_author.split(".")[-1]

    # remove spaces
    first_author = first_author.replace(" ", "")

    # get journal part of key
    # follow journal={...} in the bib entry
    journal_start = entry.find("journal={")
    journal_start += len("journal={")
    journal_end = entry.find("}", journal_start)
    journal = entry[journal_start:journal_end].strip()

    journal_key = journal_to_bibtexkey.get(journal, "unknownjournal")
    if journal_key == "unknownjournal":
        journal_key = (
            journal.lower()
            .replace(" ", "")
            .replace("&", "and")
            .replace("-", "")
            .replace(",", "")
            .replace(".", "")
        )
        print(f"Warning: Journal '{journal}' not found in mapping dictionary. Using generated key '{journal_key}'. \n")

    # find year part of key
    # after last : in the key before first , 
    year_start_index = key.rfind(":") + 1
    year = key[year_start_index:].strip()

    # check that it is a 4 digit year
    if not year[:4].isdigit():
        error = True
        error_message += f"Error: Year '{year}' not found or invalid in key.\n"

    if error:
        print("Error processing entry:\n{} \n{}".format(key, error_message))
        new_entry = entry  # return original entry on error
    else:
        # construct new key
        new_key = f"{first_author}:{journal_key}:{year}"
        # replace old key with new key in entry
        new_entry = entry[:start_index] + new_key + entry[end_index:]

    return new_entry, error

def process_book(entry):
    error = False
    error_message = ""

    # get key between { and ,
    start_index = entry.find("{") + 1

    if entry.find("year={") == -1:
        error = True
        error_message += "Year field not found in entry.\n"

    end_index = entry.find(",", start_index)

    if error:
        key = ""
    else:
        key = entry[start_index:end_index].strip()

    # get first author part of key
    # get first authors last name
    # start of key to first _ or : which ever comes first
    author_end_index = len(key)
    underscore_index = key.find("_")
    colon_index = key.find(":")

    if underscore_index != -1 and underscore_index < author_end_index:
        author_end_index = underscore_index
    if colon_index != -1 and colon_index < author_end_index:
        author_end_index = colon_index

    first_author = key[:author_end_index]

    # make first author name lowercase
    first_author = first_author.lower()

    # remove accents from first author name
    first_author = unidecode(first_author)

    # remove everything before . in first author name
    if "." in first_author:
        first_author = first_author.split(".")[-1]

    # remove spaces
    first_author = first_author.replace(" ", "")

    # find year part of key
    # after last : in the key before first , 
    year_start_index = key.rfind(":") + 1
    year = key[year_start_index:].strip()

    # check that it is a 4 digit year
    if not year[:4].isdigit():
        error = True
        error_message += f"Error: Year '{year}' not found or invalid in key.\n"

    if error:
        print("Error processing entry:\n{} \n{}".format(key, error_message))
        new_entry = entry  # return original entry on error
    else:
        # construct new key
        new_key = f"{first_author}:{year}"
        # replace old key with new key in entry
        new_entry = entry[:start_index] + new_key + entry[end_index:]

    return new_entry, error

if args.filename is not None:
    # parse the bib file line by line
    with open(args.filename, "r") as bib_file:
        lines = bib_file.readlines()
    new_lines = []
    other_lines = []
    for line in lines:
        if line.strip().startswith("@article"):
            line = line.lstrip()
            new_line, error = process_article(line)

            if not error:
                new_lines.append(new_line)
            else:
                other_line = line.strip() + "\n"
                other_lines.append(other_line)
        elif line.strip().startswith("@book") or line.strip().startswith("@inbook"):
            line = line.lstrip()
            new_line, error = process_book(line)

            if not error:
                new_lines.append(new_line)
            else:
                other_line = line.strip() + "\n"
                other_lines.append(other_line)
        else:
            other_line = line.strip() + "\n"
            other_lines.append(other_line)

    tidied_filename = args.filename.replace(".bib", "-tidied.bib")
    with open(tidied_filename, "w") as bib_file:
        bib_file.writelines(new_lines + ["\n\n"] + other_lines)
elif args.entry is not None:
    new_entry = process_article(args.entry)
    print("Processed Entry: \n \n", new_entry)
else:
    print("Please provide either a filename with -f or an entry with -i.")
    sys.exit(1)
